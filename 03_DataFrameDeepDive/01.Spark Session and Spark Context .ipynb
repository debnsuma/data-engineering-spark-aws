{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18b29e25",
   "metadata": {},
   "source": [
    "# SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8067e4bd",
   "metadata": {},
   "source": [
    "- The `SparkSession` class, defined in the `pyspark.sql` package, is the entry point\n",
    "to programming Spark with the Dataset and DataFrame APIs. \n",
    "- In order to do\n",
    "anything useful with a Spark cluster, you first need to create an instance of this\n",
    "class, which gives you access to an instance of `SparkContext`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4cd612",
   "metadata": {},
   "source": [
    "# SparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6809b1b",
   "metadata": {},
   "source": [
    "- The `SparkContext` class, defined in the `pyspark` package, is the main entry point\n",
    "for Spark functionality. \n",
    "- A `SparkContext` holds a connection to the Spark cluster\n",
    "manager and can be used to create RDDs and broadcast variables in the cluster.\n",
    "- When you create an instance of SparkSession, the SparkContext becomes available\n",
    "inside your session as an attribute, `SparkSession.sparkContext`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d5b0a5",
   "metadata": {},
   "source": [
    "### Go to the coding "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9efaa6d",
   "metadata": {},
   "source": [
    "# Creating a Spark DataFrame "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d265895",
   "metadata": {},
   "source": [
    "Different ways we can create a Spark DataFrame. All are offered by `SparkSession`\n",
    "- read \n",
    "- sql()\n",
    "- table()\n",
    "- range()\n",
    "- createDataFrame() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4c9ca3",
   "metadata": {},
   "source": [
    "### `range` Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "313187a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = false)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "|  5|\n",
      "|  6|\n",
      "|  7|\n",
      "|  8|\n",
      "|  9|\n",
      "+---+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Create a single column DF \n",
    "df1 = spark.range(10)\n",
    "df1.printSchema() \n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470ae422",
   "metadata": {},
   "source": [
    "### `createDataFrame` Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e0d1a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "my_list = [(1, \"Suman\", date(1985, 1, 1), 'Bangalore', 100.2), \\\n",
    "           (2, \"Kumar\", date(1986, 2, 2), 'Singapore', 123.4), \\\n",
    "           (3, \"Mike\", date(1990, 10, 1), 'Sydney', 110.3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f807b385",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+---------+-----+\n",
      "| _1|   _2|        _3|       _4|   _5|\n",
      "+---+-----+----------+---------+-----+\n",
      "|  1|Suman|1985-01-01|Bangalore|100.2|\n",
      "|  2|Kumar|1986-02-02|Singapore|123.4|\n",
      "|  3| Mike|1990-10-01|   Sydney|110.3|\n",
      "+---+-----+----------+---------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 2:=============================>                             (2 + 2) / 4]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "my_df = spark.createDataFrame(my_list)\n",
    "my_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00e66cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _1: long (nullable = true)\n",
      " |-- _2: string (nullable = true)\n",
      " |-- _3: date (nullable = true)\n",
      " |-- _4: string (nullable = true)\n",
      " |-- _5: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e493f19",
   "metadata": {},
   "source": [
    "#### How can we change the column name ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5a3c5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+---------+-----------+\n",
      "| id| name|       DoB|     city|blood_sugar|\n",
      "+---+-----+----------+---------+-----------+\n",
      "|  1|Suman|1985-01-01|Bangalore|      100.2|\n",
      "|  2|Kumar|1986-02-02|Singapore|      123.4|\n",
      "|  3| Mike|1990-10-01|   Sydney|      110.3|\n",
      "+---+-----+----------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# toDF() -> Transformation \n",
    "my_df = spark.createDataFrame(my_list).toDF('id', 'name', 'DoB', 'city', 'blood_sugar')\n",
    "my_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01edb97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- DoB: date (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- blood_sugar: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9633b3ed",
   "metadata": {},
   "source": [
    "#### How can we define the schema in a different way ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf2a91ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_1 = ['id', 'name', 'DoB', 'city', 'blood_sugar']\n",
    "schema_2 = 'id int, name string, DoB date, city string, blood_sugar double'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b77c3bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- DoB: date (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- blood_sugar: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.createDataFrame(my_list, schema_1).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80f5bec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- DoB: date (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- blood_sugar: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.createDataFrame(my_list, schema_2).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31ed27bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "pd_df = pd.DataFrame({'id': [1, 2, 3],\n",
    "                      'name': ['Suman', 'Kumar', 'Mike'],\n",
    "                      'DoB': [date(1985, 1, 1), date(1986, 2, 2), date(1990, 10, 1)],\n",
    "                      'city': ['Bangalore', 'SIngapore', 'Sydney'],\n",
    "                      'blood_sugar' : [140.1, 123.4, 110.3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c5535e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+---------+-----------+\n",
      "| id| name|       DoB|     city|blood_sugar|\n",
      "+---+-----+----------+---------+-----------+\n",
      "|  1|Suman|1985-01-01|Bangalore|      140.1|\n",
      "|  2|Kumar|1986-02-02|SIngapore|      123.4|\n",
      "|  3| Mike|1990-10-01|   Sydney|      110.3|\n",
      "+---+-----+----------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(pd_df, schema_2)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6aa8724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- DoB: date (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- blood_sugar: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a0d7d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
