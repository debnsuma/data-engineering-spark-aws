{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55570d8a",
   "metadata": {},
   "source": [
    "# So far we have see the following:\n",
    "- How we can create a `Database`\n",
    "- How we can create a `Table`\n",
    "- How to `load` the data from a `tempView` to a `Table` \n",
    "- And the table which we created was a `Managed Table`, and hence when we **dropped the table**:\n",
    "    - **Both the data and metadata got deleted**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91218332",
   "metadata": {},
   "source": [
    "## Types of table:\n",
    "\n",
    "**1. Managed Table** \n",
    "\n",
    "```python\n",
    "\n",
    "# Create an empty table\n",
    "spark.sql('CREATE TABLE my_db_spark.orders \\\n",
    "       (order_id integer, \\\n",
    "        order_date string, \\\n",
    "        customer_id integer, \\\n",
    "        order_status string))\n",
    "\n",
    "# Load data into the table \n",
    "spark.sql(\"INSERT INTO orders \\\n",
    "    SELECT * \\\n",
    "    FROM orders_view\")\n",
    " ```   \n",
    "            \n",
    "**2. External Table** \n",
    "```python\n",
    "# No loading of data, just point to the data location \n",
    "spark.sql('CREATE TABLE my_db_spark.orders \\\n",
    "   (order_id integer, \\\n",
    "    order_date string, \\\n",
    "    customer_id integer, \\\n",
    "    order_status string) \\\n",
    "    USING csv \\\n",
    "    LOCATION '<S3:Path>') \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb3b46a",
   "metadata": {},
   "source": [
    "## Create an `external` Table\n",
    "\n",
    "    - We dont own the data \n",
    "    - We own ONLY the metadata \n",
    "    - We can not delete the data (as many others might be using the data) \n",
    "        - When we drop, it will DROP only the meta data \n",
    "        - Even if we use TRUNCATE, it would fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d8ce09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.catalog.currentDatabase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42254f2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sql('CREATE DATABASE IF NOT EXISTS my_db_spark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df444d31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sql('USE my_db_spark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13385af3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating an external table \n",
    "\n",
    "spark.sql(\"CREATE TABLE orders \\\n",
    "           (order_id integer, \\\n",
    "            order_date string, \\\n",
    "            customer_id integer, \\\n",
    "            order_status string) \\\n",
    "            USING parquet \\\n",
    "            OPTIONS ('header'='true', 'inferSchema'='true') \\\n",
    "            LOCATION 's3://fcc-spark-example/dataset/2023/my_orders'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fdbb69-bc05-48e7-aeca-51aac8a4e04f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sql('SHOW TABLES').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5d3b21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sql('SELECT * FROM orders').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18a129c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are many different options available \n",
    "\n",
    "spark.sql(\"\"\"\n",
    "  CREATE TABLE my_db_spark.orders2 (\n",
    "    order_id integer,\n",
    "    order_date string,\n",
    "    customer_id integer,\n",
    "    order_status string\n",
    "  )\n",
    "  USING csv\n",
    "  OPTIONS (\n",
    "    'path' 's3://fcc-spark-example/dataset/2023/orders.csv',\n",
    "    'header' 'true',\n",
    "    'sep' ',',\n",
    "    'inferSchema' 'true',\n",
    "    'mode' 'FAILFAST',\n",
    "    'quote' '\"',\n",
    "    'escape' '\"',\n",
    "    'multiline' 'true',\n",
    "    'charset' 'UTF-8'\n",
    "  )\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158d29a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sql('show tables').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b9a196",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sql('DESCRIBE EXTENDED orders').show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d1c789",
   "metadata": {},
   "source": [
    "##### You can run this in a seperate shell, and we can see the data as its not an temp view\n",
    "```python\n",
    ">>> spark.sql('SHOW tables').show()\n",
    "+-----------+---------+-----------+\n",
    "|  namespace|tableName|isTemporary|\n",
    "+-----------+---------+-----------+\n",
    "|my_db_spark|   orders|      false|\n",
    "+-----------+---------+-----------+\n",
    "\n",
    ">>> \n",
    ">>> spark.sql('SELECT * FROM orders').show(5)\n",
    "+--------+--------------------+-----------+---------------+                     \n",
    "|order_id|          order_date|customer_id|   order_status|\n",
    "+--------+--------------------+-----------+---------------+\n",
    "|       1|2013-07-25 00:00:...|      11599|         CLOSED|\n",
    "|       2|2013-07-25 00:00:...|        256|PENDING_PAYMENT|\n",
    "|       3|2013-07-25 00:00:...|      12111|       COMPLETE|\n",
    "|       4|2013-07-25 00:00:...|       8827|         CLOSED|\n",
    "|       5|2013-07-25 00:00:...|      11318|       COMPLETE|\n",
    "+--------+--------------------+-----------+---------------+\n",
    "only showing top 5 rows\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee29084",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # This would FAIL \n",
    "\n",
    "spark.sql('TRUNCATE table orders')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f24485b",
   "metadata": {},
   "source": [
    "- **External Table**\n",
    "    - We ONLY own the metadata \n",
    "    - Data stays somewhere else, like here its on S3 \n",
    "    - The data may be used by others, so we dont have the rights to do anything to that data as we dont own that \n",
    "\n",
    "- **Managed Table**\n",
    "    - We OWN BOTH the metadata and data \n",
    "    - We can do whataver we want \n",
    "    - When this table is dropped, both the data and metadata is lost\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8f1138",
   "metadata": {},
   "source": [
    "### DML Operations \n",
    "    - INSERT - it works -> But its mostly for OLTP application, its not for Spark ideally\n",
    "    - UPDATE - doesnt work  (This works in Databricks, using Delta lake)\n",
    "    - DELETE - doesnt work  (This works in Databricks, using Delta lake) \n",
    "    - SELECT - Always work \n",
    "    \n",
    "    (These are as part of Open Source Apache Spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d23f478-ee6a-407c-995b-ebfb091bbbcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sql('SELECT * FROM orders').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e43f03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sql(\"INSERT INTO TABLE my_db_spark.orders VALUES (555555, '2023-05-23', 555555, 'COMPLETED')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8a43a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sql(\"INSERT INTO TABLE my_db_spark.orders VALUES (666666, '2023-05-23', 666666, 'COMPLETED')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8ce671-edd5-4262-9a01-8c46b2eeffa6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sql('SELECT * FROM orders').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ade343a-04d4-404a-9c3e-36f433547539",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We will not see ONLY the database folder\n",
    "\n",
    "!hadoop fs -ls hdfs://ip-172-31-2-35.us-east-2.compute.internal:8020/user/spark/warehouse/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5603fcf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We will not see any data here \n",
    "\n",
    "!hadoop fs -ls hdfs://ip-172-31-2-35.us-east-2.compute.internal:8020/user/spark/warehouse/my_db_spark.db/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1f4825",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sql('SELECT * FROM my_db_spark.orders WHERE order_id IN (555555, 666666)').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66e841e",
   "metadata": {},
   "source": [
    "```bash \n",
    "[hadoop@ip-172-31-2-35 ~]$ aws s3 ls s3://fcc-spark-example/dataset/2023/my_orders/\n",
    "2023-07-10 17:27:22          0 _SUCCESS\n",
    "2023-07-10 17:27:07       1277 part-00000-2733a635-a8dd-4c5f-b1e1-f8789acf6330-c000.snappy.parquet\n",
    "2023-07-10 17:27:22       1277 part-00000-775b48c5-602f-45d0-8536-e559c1737bf0-c000.snappy.parquet\n",
    "[hadoop@ip-172-31-2-35 ~]$\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b61f537",
   "metadata": {},
   "source": [
    "# Clean up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea39376",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT current_database()\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af1e2f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sql(\"DROP TABLE orders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9ce3da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sql(\"SHOW TABLES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f1e881",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sql(\"DROP DATABASE my_db_spark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170304e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sql(\"USE default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835220dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sql(\"SHOW DATABASES\").show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985822d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
