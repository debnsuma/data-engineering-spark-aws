{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "123468f6",
   "metadata": {},
   "source": [
    "# Spark Optimization\n",
    "\n",
    "\n",
    "1. `Application` level Optimization \n",
    "    - `code` optimization\n",
    "    - use of `cache`\n",
    "    - use of `reduceByKey` instead of `groupbykey`\n",
    " \n",
    "2. `Cluster` level Optimization \n",
    "    - how spark execute our code\n",
    "    - how resources are allocated across executor/container/JVM\n",
    "    - how tasks are executed, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047da821",
   "metadata": {},
   "source": [
    "# Executor \n",
    "\n",
    "## At a high level:\n",
    "\n",
    "Our intention is always to make sure that our `job` gets the right amount of `resources`\n",
    "   - Its a container of resources (`CPU` and `Memory`)\n",
    "   - 1 Node can hold more than 1 executor \n",
    "   - `Container`/`Executor`/`JVM` -> All are equivalent in Spark \n",
    "\n",
    "Lets say we have 'c' no. of cores and ''x' GB of meomory in each machine. Then,\n",
    "   - we can have (c-1 cores and x-1 GB of memory) which we can use for executors \n",
    "   - 1 core and 1 GB memory is used for background process (deamon threads) \n",
    "\n",
    "## Two strategies we can use while creating the executors \n",
    "\n",
    "   - `Thin` **Executor** : \n",
    "        - Intention is to create more executors with each executor holding `min` possible resources\n",
    "        - If a node is having 16 core CPU and 64GB memory, we can have max 16 executors with 4GB memory each \n",
    "        - We **can not have multi-threading** as each executor is having only 1 CPU core \n",
    "        - In case of `Broadcast/Shared Variables` we need to **copy the same data for multiple executors.** \n",
    "        - This type of executor is not that good \n",
    "        \n",
    "        \n",
    "   - `Fat` **Executor** :\n",
    "        - Intention is to give `max` resources to each executor \n",
    "        - If a node is having 16 core CPU and 64GB memory, we can have 1 single executor with all its CPU and Memory\n",
    "        - We can **have multithreading, but lot of multithreading is also not recommended**, we should have a balanced approch \n",
    "        - It is observed that, if the executor is holding more than 5 CPU Cores then HDFS throughput suffers \n",
    "        - If the executor holds very large amount of memory, then GC collection may take a lot of time. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a792d9",
   "metadata": {},
   "source": [
    "# Recommendation \n",
    "What would be the best way to operate, assume **each worker node have (16 Core CPU and 64 GB memory):**\n",
    "\n",
    "#### What we want ?\n",
    "   - We want multi-threading within a executor \n",
    "   - At the same time we want the HDFS throughput NOT to suffer \n",
    "   \n",
    "#### How can we go from here ?\n",
    "   - 5 is the right choice of no. of CPU cores within each executor \n",
    "   - So, if we have 16 Core CPU and 64 GB memory in a node, then **within each node**\n",
    "       - we can have 3 executor\n",
    "       - within this 21GB RAM some part of it will go to `Overhead (Off Heap Memory)`\n",
    "           - `Overhead (Off Heap Memory)` : The memory which is not part of the JVM (its RAW memory)\n",
    "           - How much is that ? Its `max(384MB, 7% of executor memory) = 1.5GB` (Overhead/Off Heap memory) \n",
    "           - This memory **wont be part of the executor/container**\n",
    "           - So, **each executor would have effectively 21-1.5 ~ 19.5GB memory** \n",
    "       - So, ultimately **each executor would have 5 CPU cores and 19.5 GB memory**\n",
    "\n",
    "![mem_arch](../img/mem_arch.png)\n",
    "\n",
    "#### Now, lets assume we have a 10 Node cluster (Worker Nodes) \n",
    "\n",
    "  - Then we will have **30 Executors (10*3)**\n",
    "  - Each executor would have **5 CPU cores and ~19.5GB memory**\n",
    "  - Out of this 30 Executor, **1 executor would be taken by YARN Application**, so effectively we would have **29 executors**\n",
    "  \n",
    "#### Also, if we summarise, \n",
    " - we know that the `number of tasks created` will be **equal to** the `number of partitions (of our data)`\n",
    " - but the `number of tasks executed in parallel` will **depend on** the `number of CPU cores available in each executor`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7874be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "10 Partition \n",
    "10 tasks ===> We have 1 Excutor with only 2 CPU (10 tasks in paraller (this will happen)) \n",
    "\n",
    "1, 2 ====> 3, 4 ====> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258a1d99-9ec8-491d-933d-3d7f7634ded1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
