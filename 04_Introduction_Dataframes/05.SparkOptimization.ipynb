{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "123468f6",
   "metadata": {},
   "source": [
    "# Spark Optimization\n",
    "\n",
    "1. Application Level Optimization \n",
    "    - code\n",
    "    - use of cache \n",
    "    - use of reduceByKey instead of groupbykey\n",
    "    \n",
    "    \n",
    "2. Cluster level Optimization \n",
    "    - how spark execute our code\n",
    "    - what is an executor/container/jvm\n",
    "    - how tasks are executed, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047da821",
   "metadata": {},
   "source": [
    "# Executor \n",
    "\n",
    "At a high level:\n",
    "   - Its a container of resources (CPU and Memory)\n",
    "   - 1 Node can hold more than 1 executor \n",
    "   - Container/Executor/JVM -> All are equivalent in Spark \n",
    "\n",
    "Lets say we have 'c' no. of cores and ''x' GB of meomory in each machine. Then,\n",
    "   - we can have (c-1 cores and x-1 GB of memory) which we can use for executors \n",
    "   - 1 core and 1 GB memory is used for background process (deamon threads) \n",
    "\n",
    "Two strategies we can use while creating the executors \n",
    "\n",
    "   - `Thin` **Executor** : \n",
    "        - Intention is to create more executors with each executor holding min possible resources\n",
    "        - If a node is having 16 core CPU and 64GB memory, we can have max 15 executors with 4GB memory each \n",
    "        - We can not have multi-threading as each executor is having only 1 CPU core \n",
    "        - In case of `Broadcast/Shared Variables` we need to copy the same data for multiple executors. \n",
    "        - This type of executor is not that good \n",
    "        \n",
    "        \n",
    "   - `Fat` **Executor** :\n",
    "        - Intention is to give max resources to each executor \n",
    "        - If a node is having 16 core CPU and 64GB memory, we can have 1 single executor with all its CPU and Memory\n",
    "        - It is observed that if the executor is holding more than 5 CPU Cores then HDFS throughput suffers \n",
    "        - Lot of multithreading is also not recommended, we should have a balanced approch \n",
    "        - If the executor holds very large amount of memory, then GC collection may take a lot of time. \n",
    "\n",
    "\n",
    "What would be the best way to operate, assume each worker node have (16 Core CPU and 64 GB memory):\n",
    "\n",
    "   - We want multi-threading within a executor \n",
    "   - At the same time we want the HDFS throughput NOT to suffer \n",
    "   - 5 is the right choice of no. of CPU cores within each executor \n",
    "   - So, if we have 16 Core CPU and 64 GB memory in a node, then\n",
    "       - we can have 3 executor\n",
    "       - each executor would have 5 CPU cores (15/5) and 21 GB memory (63/3) \n",
    "       - within this 21GB RAM some part of it will go to Overhead (Off Heap Memory)\n",
    "          - max(384MB, 7% of executor memory) = 1.5GB (Overhead/Off Heap memory) \n",
    "          - This memory wont be part of the executor/container\n",
    "          - So, each executor would have effectively 21-1.5 = 19.5GB memory \n",
    "            \n",
    "Now, lets assume we have a 10 Node cluster (Worker Nodes) \n",
    "\n",
    "  - Then we will have 30 Executors (10 * 3) \n",
    "  - Each executor would have 5 CPU cores and ~19.5GB Memory \n",
    "  - Out of this 30 Executor, 1 executor would be taken by YARN Application, so effectively we would have 29 executors \n",
    "  \n",
    "Also, if we summarise, we know that the number of tasks created will be equal to the number of partitions (of our data), but the number of tasks executed in parallel will depend on the number of CPU cores available in each executor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099a95b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
