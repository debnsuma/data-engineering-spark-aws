{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8c7d777",
   "metadata": {},
   "source": [
    "# Dataframe Deep Dive (Part 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3787618d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-2-35.us-east-2.compute.internal:4045\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0-amzn-1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fad7d93ad10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f7c4e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-2-35.us-east-2.compute.internal:4045\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0-amzn-1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=yarn appName=PySparkShell>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150fb5eb",
   "metadata": {},
   "source": [
    "## Dataframe `Schema`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa02ac4e",
   "metadata": {},
   "source": [
    "#### With inferSchema = `True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c40b6364",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data_set = 's3://fcc-spark-example/dataset/2023/orders.csv'\n",
    "\n",
    "df = (spark.read\n",
    "           .format('csv')\n",
    "           .option('header', 'true')\n",
    "           .option('inferSchema', 'true')\n",
    "           .load(data_set)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e71f3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|\n",
      "|       6|2013-07-25 00:00:00|             7130|       COMPLETE|\n",
      "|       7|2013-07-25 00:00:00|             4530|       COMPLETE|\n",
      "|       8|2013-07-25 00:00:00|             2911|     PROCESSING|\n",
      "|       9|2013-07-25 00:00:00|             5657|PENDING_PAYMENT|\n",
      "|      10|2013-07-25 00:00:00|             5648|PENDING_PAYMENT|\n",
      "|      11|2013-07-25 00:00:00|              918| PAYMENT_REVIEW|\n",
      "|      12|2013-07-25 00:00:00|             1837|         CLOSED|\n",
      "|      13|2013-07-25 00:00:00|             9149|PENDING_PAYMENT|\n",
      "|      14|2013-07-25 00:00:00|             9842|     PROCESSING|\n",
      "|      15|2013-07-25 00:00:00|             2568|       COMPLETE|\n",
      "|      16|2013-07-25 00:00:00|             7276|PENDING_PAYMENT|\n",
      "|      17|2013-07-25 00:00:00|             2667|       COMPLETE|\n",
      "|      18|2013-07-25 00:00:00|             1205|         CLOSED|\n",
      "|      19|2013-07-25 00:00:00|             9488|PENDING_PAYMENT|\n",
      "|      20|2013-07-25 00:00:00|             9198|     PROCESSING|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f727d7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- order_date: timestamp (nullable = true)\n",
      " |-- order_customer_id: integer (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5e4501",
   "metadata": {},
   "source": [
    "#### With `inferSchema` = `True` and `samplingRatio` = `<some ratio>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c4e1c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data_set = 's3://fcc-spark-example/dataset/2023/orders.csv'\n",
    "\n",
    "df = (spark.read\n",
    "           .format('csv')\n",
    "           .option('header', 'true')\n",
    "           .option('inferSchema', 'true')\n",
    "           .option('samplingRatio', 0.01)\n",
    "           .load(data_set)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0543ad8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------------+---------------+\n",
      "|order_id|         order_date|order_customer_id|   order_status|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "|       1|2013-07-25 00:00:00|            11599|         CLOSED|\n",
      "|       2|2013-07-25 00:00:00|              256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:00|            12111|       COMPLETE|\n",
      "|       4|2013-07-25 00:00:00|             8827|         CLOSED|\n",
      "|       5|2013-07-25 00:00:00|            11318|       COMPLETE|\n",
      "|       6|2013-07-25 00:00:00|             7130|       COMPLETE|\n",
      "|       7|2013-07-25 00:00:00|             4530|       COMPLETE|\n",
      "|       8|2013-07-25 00:00:00|             2911|     PROCESSING|\n",
      "|       9|2013-07-25 00:00:00|             5657|PENDING_PAYMENT|\n",
      "|      10|2013-07-25 00:00:00|             5648|PENDING_PAYMENT|\n",
      "|      11|2013-07-25 00:00:00|              918| PAYMENT_REVIEW|\n",
      "|      12|2013-07-25 00:00:00|             1837|         CLOSED|\n",
      "|      13|2013-07-25 00:00:00|             9149|PENDING_PAYMENT|\n",
      "|      14|2013-07-25 00:00:00|             9842|     PROCESSING|\n",
      "|      15|2013-07-25 00:00:00|             2568|       COMPLETE|\n",
      "|      16|2013-07-25 00:00:00|             7276|PENDING_PAYMENT|\n",
      "|      17|2013-07-25 00:00:00|             2667|       COMPLETE|\n",
      "|      18|2013-07-25 00:00:00|             1205|         CLOSED|\n",
      "|      19|2013-07-25 00:00:00|             9488|PENDING_PAYMENT|\n",
      "|      20|2013-07-25 00:00:00|             9198|     PROCESSING|\n",
      "+--------+-------------------+-----------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3512061b",
   "metadata": {},
   "source": [
    "#### Enforcing the `schema`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9edc2260",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = 's3://fcc-spark-example/dataset/2023/orders/orders_1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29609db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_schema = (spark.read\n",
    "                           .format('csv')\n",
    "                           .load(data_set)\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9189faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-----+---------------+\n",
      "|_c0|                 _c1|  _c2|            _c3|\n",
      "+---+--------------------+-----+---------------+\n",
      "|  1|2013-07-25T00:00:...|11599|         CLOSED|\n",
      "|  2|2013-07-25T00:00:...|  256|PENDING_PAYMENT|\n",
      "|  3|2013-07-25T00:00:...|12111|       COMPLETE|\n",
      "|  4|2013-07-25T00:00:...| 8827|         CLOSED|\n",
      "|  5|2013-07-25T00:00:...|11318|       COMPLETE|\n",
      "|  6|2013-07-25T00:00:...| 7130|       COMPLETE|\n",
      "|  7|2013-07-25T00:00:...| 4530|       COMPLETE|\n",
      "|  8|2013-07-25T00:00:...| 2911|     PROCESSING|\n",
      "|  9|2013-07-25T00:00:...| 5657|PENDING_PAYMENT|\n",
      "| 10|2013-07-25T00:00:...| 5648|PENDING_PAYMENT|\n",
      "| 11|2013-07-25T00:00:...|  918| PAYMENT_REVIEW|\n",
      "| 12|2013-07-25T00:00:...| 1837|         CLOSED|\n",
      "| 13|2013-07-25T00:00:...| 9149|PENDING_PAYMENT|\n",
      "| 14|2013-07-25T00:00:...| 9842|     PROCESSING|\n",
      "| 15|2013-07-25T00:00:...| 2568|       COMPLETE|\n",
      "| 16|2013-07-25T00:00:...| 7276|PENDING_PAYMENT|\n",
      "| 17|2013-07-25T00:00:...| 2667|       COMPLETE|\n",
      "| 18|2013-07-25T00:00:...| 1205|         CLOSED|\n",
      "| 19|2013-07-25T00:00:...| 9488|PENDING_PAYMENT|\n",
      "| 20|2013-07-25T00:00:...| 9198|     PROCESSING|\n",
      "+---+--------------------+-----+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_without_schema.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee452ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_without_schema.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911235a2",
   "metadata": {},
   "source": [
    "There are 2 ways we can define the schema : "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2937d5f3",
   "metadata": {},
   "source": [
    "#### Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac36dc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_schema = 'order_id long, order_date date, order_customer_id long, order_status string'\n",
    "\n",
    "df_with_schema = (spark.read\n",
    "                           .format('csv')\n",
    "                           .schema(orders_schema)\n",
    "                           .load(data_set)\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "319cb66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------------+---------------+\n",
      "|order_id|order_date|order_customer_id|   order_status|\n",
      "+--------+----------+-----------------+---------------+\n",
      "|       1|2013-07-25|            11599|         CLOSED|\n",
      "|       2|2013-07-25|              256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25|            12111|       COMPLETE|\n",
      "|       4|2013-07-25|             8827|         CLOSED|\n",
      "|       5|2013-07-25|            11318|       COMPLETE|\n",
      "|       6|2013-07-25|             7130|       COMPLETE|\n",
      "|       7|2013-07-25|             4530|       COMPLETE|\n",
      "|       8|2013-07-25|             2911|     PROCESSING|\n",
      "|       9|2013-07-25|             5657|PENDING_PAYMENT|\n",
      "|      10|2013-07-25|             5648|PENDING_PAYMENT|\n",
      "|      11|2013-07-25|              918| PAYMENT_REVIEW|\n",
      "|      12|2013-07-25|             1837|         CLOSED|\n",
      "|      13|2013-07-25|             9149|PENDING_PAYMENT|\n",
      "|      14|2013-07-25|             9842|     PROCESSING|\n",
      "|      15|2013-07-25|             2568|       COMPLETE|\n",
      "|      16|2013-07-25|             7276|PENDING_PAYMENT|\n",
      "|      17|2013-07-25|             2667|       COMPLETE|\n",
      "|      18|2013-07-25|             1205|         CLOSED|\n",
      "|      19|2013-07-25|             9488|PENDING_PAYMENT|\n",
      "|      20|2013-07-25|             9198|     PROCESSING|\n",
      "+--------+----------+-----------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_with_schema.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40b5f36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: long (nullable = true)\n",
      " |-- order_date: date (nullable = true)\n",
      " |-- order_customer_id: long (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_with_schema.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7d8339f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we load some schema which doesnt match with the data \n",
    "# It will full the columns with NULLs \n",
    "\n",
    "orders_schema = 'order_id long, order_date date, order_customer_id long, order_status long'\n",
    "\n",
    "df_with_schema = (spark.read\n",
    "                           .format('csv')\n",
    "                           .schema(orders_schema)\n",
    "                           .load(data_set)\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0060d9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------------+------------+\n",
      "|order_id|order_date|order_customer_id|order_status|\n",
      "+--------+----------+-----------------+------------+\n",
      "|       1|2013-07-25|            11599|        null|\n",
      "|       2|2013-07-25|              256|        null|\n",
      "|       3|2013-07-25|            12111|        null|\n",
      "|       4|2013-07-25|             8827|        null|\n",
      "|       5|2013-07-25|            11318|        null|\n",
      "|       6|2013-07-25|             7130|        null|\n",
      "|       7|2013-07-25|             4530|        null|\n",
      "|       8|2013-07-25|             2911|        null|\n",
      "|       9|2013-07-25|             5657|        null|\n",
      "|      10|2013-07-25|             5648|        null|\n",
      "|      11|2013-07-25|              918|        null|\n",
      "|      12|2013-07-25|             1837|        null|\n",
      "|      13|2013-07-25|             9149|        null|\n",
      "|      14|2013-07-25|             9842|        null|\n",
      "|      15|2013-07-25|             2568|        null|\n",
      "|      16|2013-07-25|             7276|        null|\n",
      "|      17|2013-07-25|             2667|        null|\n",
      "|      18|2013-07-25|             1205|        null|\n",
      "|      19|2013-07-25|             9488|        null|\n",
      "|      20|2013-07-25|             9198|        null|\n",
      "+--------+----------+-----------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_with_schema.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d313b749",
   "metadata": {},
   "source": [
    "#### Method 2 (using `StructType`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb81426e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------------+---------------+\n",
      "|order_id|order_date|order_customer_id|   order_status|\n",
      "+--------+----------+-----------------+---------------+\n",
      "|       1|2013-07-25|            11599|         CLOSED|\n",
      "|       2|2013-07-25|              256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25|            12111|       COMPLETE|\n",
      "|       4|2013-07-25|             8827|         CLOSED|\n",
      "|       5|2013-07-25|            11318|       COMPLETE|\n",
      "|       6|2013-07-25|             7130|       COMPLETE|\n",
      "|       7|2013-07-25|             4530|       COMPLETE|\n",
      "|       8|2013-07-25|             2911|     PROCESSING|\n",
      "|       9|2013-07-25|             5657|PENDING_PAYMENT|\n",
      "|      10|2013-07-25|             5648|PENDING_PAYMENT|\n",
      "|      11|2013-07-25|              918| PAYMENT_REVIEW|\n",
      "|      12|2013-07-25|             1837|         CLOSED|\n",
      "|      13|2013-07-25|             9149|PENDING_PAYMENT|\n",
      "|      14|2013-07-25|             9842|     PROCESSING|\n",
      "|      15|2013-07-25|             2568|       COMPLETE|\n",
      "|      16|2013-07-25|             7276|PENDING_PAYMENT|\n",
      "|      17|2013-07-25|             2667|       COMPLETE|\n",
      "|      18|2013-07-25|             1205|         CLOSED|\n",
      "|      19|2013-07-25|             9488|PENDING_PAYMENT|\n",
      "|      20|2013-07-25|             9198|     PROCESSING|\n",
      "+--------+----------+-----------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "data_set = 's3://fcc-spark-example/dataset/2023/orders/orders_1.csv'\n",
    "\n",
    "orders_schema = StructType([\n",
    "                            StructField('order_id', LongType()),\n",
    "                            StructField('order_date', DateType()),\n",
    "                            StructField('order_customer_id', IntegerType()),\n",
    "                            StructField('order_status', StringType())\n",
    "                        ])\n",
    "\n",
    "df = (spark.read\n",
    "           .format('csv')\n",
    "           .schema(orders_schema)\n",
    "           .load(data_set)\n",
    "     )\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49386065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: long (nullable = true)\n",
      " |-- order_date: date (nullable = true)\n",
      " |-- order_customer_id: integer (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a95086de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------------+---------------+\n",
      "|order_id|order_date|order_customer_id|   order_status|\n",
      "+--------+----------+-----------------+---------------+\n",
      "|       1|2013-07-25|            11599|         CLOSED|\n",
      "|       2|2013-07-25|              256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25|            12111|       COMPLETE|\n",
      "|       4|2013-07-25|             8827|         CLOSED|\n",
      "|       5|2013-07-25|            11318|       COMPLETE|\n",
      "|       6|2013-07-25|             7130|       COMPLETE|\n",
      "|       7|2013-07-25|             4530|       COMPLETE|\n",
      "|       8|2013-07-25|             2911|     PROCESSING|\n",
      "|       9|2013-07-25|             5657|PENDING_PAYMENT|\n",
      "|      10|2013-07-25|             5648|PENDING_PAYMENT|\n",
      "|      11|2013-07-25|              918| PAYMENT_REVIEW|\n",
      "|      12|2013-07-25|             1837|         CLOSED|\n",
      "|      13|2013-07-25|             9149|PENDING_PAYMENT|\n",
      "|      14|2013-07-25|             9842|     PROCESSING|\n",
      "|      15|2013-07-25|             2568|       COMPLETE|\n",
      "|      16|2013-07-25|             7276|PENDING_PAYMENT|\n",
      "|      17|2013-07-25|             2667|       COMPLETE|\n",
      "|      18|2013-07-25|             1205|         CLOSED|\n",
      "|      19|2013-07-25|             9488|PENDING_PAYMENT|\n",
      "|      20|2013-07-25|             9198|     PROCESSING|\n",
      "+--------+----------+-----------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "data_set = 's3://fcc-spark-example/dataset/2023/orders/orders_1.csv'\n",
    "\n",
    "orders_schema = StructType([\n",
    "                            StructField('order_id', LongType(), False),\n",
    "                            StructField('order_date', DateType(), False),\n",
    "                            StructField('order_customer_id', IntegerType(), False),\n",
    "                            StructField('order_status', StringType(), False)\n",
    "                        ])\n",
    "\n",
    "df = (spark.read\n",
    "           .format('csv')\n",
    "           .schema(orders_schema)\n",
    "           .load(data_set)\n",
    "     )\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a8cfc1",
   "metadata": {},
   "source": [
    "In PySpark, the nullable parameter in the schema definition using StructType does not enforce non-nullability in the DataFrame. It is primarily used as a hint for optimization purposes and does not restrict the presence of null values in the columns.\n",
    "\n",
    "Even if you set nullable=False for the fields in the schema definition, it does not guarantee that the corresponding columns in the DataFrame will not contain null values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "403c6c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------------+------------+\n",
      "|order_id|order_date|order_customer_id|order_status|\n",
      "+--------+----------+-----------------+------------+\n",
      "|   68884|      null|             null|    COMPLETE|\n",
      "+--------+----------+-----------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "data_set = 's3://fcc-spark-example/dataset/2023/orders/orders_1.csv'\n",
    "\n",
    "orders_schema = (StructType()\n",
    "                 .add(StructField('order_id', LongType(), nullable=False))\n",
    "                 .add(StructField('order_date', DateType(), nullable=False))\n",
    "                 .add(StructField('order_customer_id', IntegerType(), nullable=False))\n",
    "                 .add(StructField('order_status', StringType(), nullable=False))\n",
    "                )\n",
    "\n",
    "df = (spark.read\n",
    "           .format('csv')\n",
    "           .schema(orders_schema)\n",
    "           .load(data_set)\n",
    "     )\n",
    "\n",
    "\n",
    "df_filtered = df.filter(F.col('order_date').isNull())\n",
    "df_filtered.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d87226",
   "metadata": {},
   "source": [
    "### `Date` Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b58ececb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = 's3://fcc-spark-example/dataset/2023/orders/orders_2.csv'\n",
    "\n",
    "orders_schema = (StructType()\n",
    "                 .add(StructField('order_id', LongType()))\n",
    "                 .add(StructField('order_date', DateType()))\n",
    "                 .add(StructField('order_customer_id', IntegerType()))\n",
    "                 .add(StructField('order_status', StringType()))\n",
    "                )\n",
    "\n",
    "df = (spark.read\n",
    "           .format('csv')\n",
    "           .schema(orders_schema)\n",
    "           .load(data_set)\n",
    "     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbc55044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will error out  \n",
    "#df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24cc85f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (spark.read\n",
    "           .format('csv')\n",
    "           .option('inferSchema', True)\n",
    "           .load(data_set)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9050e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-----+---------------+\n",
      "|_c0|       _c1|  _c2|            _c3|\n",
      "+---+----------+-----+---------------+\n",
      "|  1|07-25-2013|11599|         CLOSED|\n",
      "|  2|07-25-2013|  256|PENDING_PAYMENT|\n",
      "|  3|07-25-2013|12111|       COMPLETE|\n",
      "|  4|07-25-2013| 8827|         CLOSED|\n",
      "|  5|07-25-2013|11318|       COMPLETE|\n",
      "|  6|07-25-2013| 7130|       COMPLETE|\n",
      "|  7|07-25-2013| 4530|       COMPLETE|\n",
      "|  8|07-25-2013| 2911|     PROCESSING|\n",
      "|  9|07-25-2013| 5657|PENDING_PAYMENT|\n",
      "| 10|07-25-2013| 5648|PENDING_PAYMENT|\n",
      "| 11|07-25-2013|  918| PAYMENT_REVIEW|\n",
      "| 12|07-25-2013| 1837|         CLOSED|\n",
      "| 13|07-25-2013| 9149|PENDING_PAYMENT|\n",
      "| 14|07-25-2013| 9842|     PROCESSING|\n",
      "| 15|07-25-2013| 2568|       COMPLETE|\n",
      "| 16|07-25-2013| 7276|PENDING_PAYMENT|\n",
      "| 17|07-25-2013| 2667|       COMPLETE|\n",
      "| 18|07-25-2013| 1205|         CLOSED|\n",
      "| 19|07-25-2013| 9488|PENDING_PAYMENT|\n",
      "| 20|07-25-2013| 9198|     PROCESSING|\n",
      "+---+----------+-----+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96e7d483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: integer (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c2104e",
   "metadata": {},
   "source": [
    "Two ways to deal with this:\n",
    "    \n",
    "    - Load using `String` and later on change it \n",
    "    - Somehow inform Spark about the exact format of the date schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ca2c60",
   "metadata": {},
   "source": [
    "#### Load using `String`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5207cbab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------------+---------------+\n",
      "|order_id|order_date|order_customer_id|   order_status|\n",
      "+--------+----------+-----------------+---------------+\n",
      "|       1|07-25-2013|            11599|         CLOSED|\n",
      "|       2|07-25-2013|              256|PENDING_PAYMENT|\n",
      "|       3|07-25-2013|            12111|       COMPLETE|\n",
      "|       4|07-25-2013|             8827|         CLOSED|\n",
      "|       5|07-25-2013|            11318|       COMPLETE|\n",
      "|       6|07-25-2013|             7130|       COMPLETE|\n",
      "|       7|07-25-2013|             4530|       COMPLETE|\n",
      "|       8|07-25-2013|             2911|     PROCESSING|\n",
      "|       9|07-25-2013|             5657|PENDING_PAYMENT|\n",
      "|      10|07-25-2013|             5648|PENDING_PAYMENT|\n",
      "|      11|07-25-2013|              918| PAYMENT_REVIEW|\n",
      "|      12|07-25-2013|             1837|         CLOSED|\n",
      "|      13|07-25-2013|             9149|PENDING_PAYMENT|\n",
      "|      14|07-25-2013|             9842|     PROCESSING|\n",
      "|      15|07-25-2013|             2568|       COMPLETE|\n",
      "|      16|07-25-2013|             7276|PENDING_PAYMENT|\n",
      "|      17|07-25-2013|             2667|       COMPLETE|\n",
      "|      18|07-25-2013|             1205|         CLOSED|\n",
      "|      19|07-25-2013|             9488|PENDING_PAYMENT|\n",
      "|      20|07-25-2013|             9198|     PROCESSING|\n",
      "+--------+----------+-----------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1 : Load using StringType\n",
    "\n",
    "data_set = 's3://fcc-spark-example/dataset/2023/orders/orders_2.csv'\n",
    "\n",
    "orders_schema = (StructType()\n",
    "                 .add(StructField('order_id', LongType()))\n",
    "                 .add(StructField('order_date', StringType()))\n",
    "                 .add(StructField('order_customer_id', IntegerType()))\n",
    "                 .add(StructField('order_status', StringType()))\n",
    "                )\n",
    "\n",
    "df = (spark.read\n",
    "           .format('csv')\n",
    "           .schema(orders_schema)\n",
    "           .load(data_set)\n",
    "     )\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0e94975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: long (nullable = true)\n",
      " |-- order_date: string (nullable = true)\n",
      " |-- order_customer_id: integer (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea1790ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 : Perform the transformation to convert the data into the right format \n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "df_transformed = df.withColumn('order_date', F.to_date(F.col('order_date'), \"MM-dd-yyyy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b32e6c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------------+---------------+\n",
      "|order_id|order_date|order_customer_id|   order_status|\n",
      "+--------+----------+-----------------+---------------+\n",
      "|       1|2013-07-25|            11599|         CLOSED|\n",
      "|       2|2013-07-25|              256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25|            12111|       COMPLETE|\n",
      "|       4|2013-07-25|             8827|         CLOSED|\n",
      "|       5|2013-07-25|            11318|       COMPLETE|\n",
      "|       6|2013-07-25|             7130|       COMPLETE|\n",
      "|       7|2013-07-25|             4530|       COMPLETE|\n",
      "|       8|2013-07-25|             2911|     PROCESSING|\n",
      "|       9|2013-07-25|             5657|PENDING_PAYMENT|\n",
      "|      10|2013-07-25|             5648|PENDING_PAYMENT|\n",
      "|      11|2013-07-25|              918| PAYMENT_REVIEW|\n",
      "|      12|2013-07-25|             1837|         CLOSED|\n",
      "|      13|2013-07-25|             9149|PENDING_PAYMENT|\n",
      "|      14|2013-07-25|             9842|     PROCESSING|\n",
      "|      15|2013-07-25|             2568|       COMPLETE|\n",
      "|      16|2013-07-25|             7276|PENDING_PAYMENT|\n",
      "|      17|2013-07-25|             2667|       COMPLETE|\n",
      "|      18|2013-07-25|             1205|         CLOSED|\n",
      "|      19|2013-07-25|             9488|PENDING_PAYMENT|\n",
      "|      20|2013-07-25|             9198|     PROCESSING|\n",
      "+--------+----------+-----------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_transformed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a8209c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------------+---------------+\n",
      "|order_id|order_date|order_customer_id|   order_status|\n",
      "+--------+----------+-----------------+---------------+\n",
      "|       1|07-25-2013|            11599|         CLOSED|\n",
      "|       2|07-25-2013|              256|PENDING_PAYMENT|\n",
      "|       3|07-25-2013|            12111|       COMPLETE|\n",
      "|       4|07-25-2013|             8827|         CLOSED|\n",
      "|       5|07-25-2013|            11318|       COMPLETE|\n",
      "|       6|07-25-2013|             7130|       COMPLETE|\n",
      "|       7|07-25-2013|             4530|       COMPLETE|\n",
      "|       8|07-25-2013|             2911|     PROCESSING|\n",
      "|       9|07-25-2013|             5657|PENDING_PAYMENT|\n",
      "|      10|07-25-2013|             5648|PENDING_PAYMENT|\n",
      "|      11|07-25-2013|              918| PAYMENT_REVIEW|\n",
      "|      12|07-25-2013|             1837|         CLOSED|\n",
      "|      13|07-25-2013|             9149|PENDING_PAYMENT|\n",
      "|      14|07-25-2013|             9842|     PROCESSING|\n",
      "|      15|07-25-2013|             2568|       COMPLETE|\n",
      "|      16|07-25-2013|             7276|PENDING_PAYMENT|\n",
      "|      17|07-25-2013|             2667|       COMPLETE|\n",
      "|      18|07-25-2013|             1205|         CLOSED|\n",
      "|      19|07-25-2013|             9488|PENDING_PAYMENT|\n",
      "|      20|07-25-2013|             9198|     PROCESSING|\n",
      "+--------+----------+-----------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Old df with string dataType\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "805da157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------------+---------------+\n",
      "|order_id|order_date|order_customer_id|   order_status|\n",
      "+--------+----------+-----------------+---------------+\n",
      "|       1|      null|            11599|         CLOSED|\n",
      "|       2|      null|              256|PENDING_PAYMENT|\n",
      "|       3|      null|            12111|       COMPLETE|\n",
      "|       4|      null|             8827|         CLOSED|\n",
      "|       5|      null|            11318|       COMPLETE|\n",
      "|       6|      null|             7130|       COMPLETE|\n",
      "|       7|      null|             4530|       COMPLETE|\n",
      "|       8|      null|             2911|     PROCESSING|\n",
      "|       9|      null|             5657|PENDING_PAYMENT|\n",
      "|      10|      null|             5648|PENDING_PAYMENT|\n",
      "|      11|      null|              918| PAYMENT_REVIEW|\n",
      "|      12|      null|             1837|         CLOSED|\n",
      "|      13|      null|             9149|PENDING_PAYMENT|\n",
      "|      14|      null|             9842|     PROCESSING|\n",
      "|      15|      null|             2568|       COMPLETE|\n",
      "|      16|      null|             7276|PENDING_PAYMENT|\n",
      "|      17|      null|             2667|       COMPLETE|\n",
      "|      18|      null|             1205|         CLOSED|\n",
      "|      19|      null|             9488|PENDING_PAYMENT|\n",
      "|      20|      null|             9198|     PROCESSING|\n",
      "+--------+----------+-----------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# If we parse WRONG format \n",
    "\n",
    "data_set = 's3://fcc-spark-example/dataset/2023/orders/orders_2.csv'\n",
    "\n",
    "orders_schema = (StructType()\n",
    "                 .add(StructField('order_id', LongType()))\n",
    "                 .add(StructField('order_date', StringType()))\n",
    "                 .add(StructField('order_customer_id', IntegerType()))\n",
    "                 .add(StructField('order_status', StringType()))\n",
    "                )\n",
    "\n",
    "df = (spark.read\n",
    "           .format('csv')\n",
    "           .schema(orders_schema)\n",
    "           .load(data_set)\n",
    "     )\n",
    "\n",
    "df_transformed = df.withColumn('order_date', F.to_date(F.col('order_date'), \"dd-MM-yyyy\"))\n",
    "\n",
    "df_transformed.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31c6f34",
   "metadata": {},
   "source": [
    "#### Loading using `dateFormat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "592eae4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------------+---------------+\n",
      "|order_id|order_date|order_customer_id|   order_status|\n",
      "+--------+----------+-----------------+---------------+\n",
      "|       1|2013-07-25|            11599|         CLOSED|\n",
      "|       2|2013-07-25|              256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25|            12111|       COMPLETE|\n",
      "|       4|2013-07-25|             8827|         CLOSED|\n",
      "|       5|2013-07-25|            11318|       COMPLETE|\n",
      "|       6|2013-07-25|             7130|       COMPLETE|\n",
      "|       7|2013-07-25|             4530|       COMPLETE|\n",
      "|       8|2013-07-25|             2911|     PROCESSING|\n",
      "|       9|2013-07-25|             5657|PENDING_PAYMENT|\n",
      "|      10|2013-07-25|             5648|PENDING_PAYMENT|\n",
      "|      11|2013-07-25|              918| PAYMENT_REVIEW|\n",
      "|      12|2013-07-25|             1837|         CLOSED|\n",
      "|      13|2013-07-25|             9149|PENDING_PAYMENT|\n",
      "|      14|2013-07-25|             9842|     PROCESSING|\n",
      "|      15|2013-07-25|             2568|       COMPLETE|\n",
      "|      16|2013-07-25|             7276|PENDING_PAYMENT|\n",
      "|      17|2013-07-25|             2667|       COMPLETE|\n",
      "|      18|2013-07-25|             1205|         CLOSED|\n",
      "|      19|2013-07-25|             9488|PENDING_PAYMENT|\n",
      "|      20|2013-07-25|             9198|     PROCESSING|\n",
      "+--------+----------+-----------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_set = 's3://fcc-spark-example/dataset/2023/orders/orders_2.csv'\n",
    "\n",
    "orders_schema = (StructType()\n",
    "                 .add(StructField('order_id', LongType()))\n",
    "                 .add(StructField('order_date', DateType()))\n",
    "                 .add(StructField('order_customer_id', IntegerType()))\n",
    "                 .add(StructField('order_status', StringType()))\n",
    "                )\n",
    "\n",
    "df = (spark.read\n",
    "           .format('csv')\n",
    "           .schema(orders_schema)\n",
    "           .option('dateFormat', 'MM-dd-yyyy')\n",
    "           .load(data_set)\n",
    "     )\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85f0892",
   "metadata": {},
   "source": [
    "\n",
    "Similarly if the column has integers and string, and we load it as a IntegerType, we will get the data as NULL \n",
    "\n",
    "```python\n",
    "+--------+----------+-----------------+---------------+\n",
    "|order_id|order_date|order_customer_id|   order_status|\n",
    "+--------+----------+-----------------+---------------+\n",
    "|       1|2013-07-25|            11599|         CLOSED|\n",
    "|       2|2013-07-25|              256|PENDING_PAYMENT|\n",
    "|       3|2013-07-25|            12111|       COMPLETE|\n",
    "|       4|2013-07-25|            aaaaa|         CLOSED|\n",
    "|       5|2013-07-25|            11318|       COMPLETE|\n",
    "|       6|2013-07-25|             bbbb|       COMPLETE|\n",
    "|       7|2013-07-25|             4530|       COMPLETE|\n",
    "+--------+----------+-----------------+---------------+\n",
    "```\n",
    "We will get : \n",
    "\n",
    "```python\n",
    "+--------+----------+-----------------+---------------+\n",
    "|order_id|order_date|order_customer_id|   order_status|\n",
    "+--------+----------+-----------------+---------------+\n",
    "|       1|2013-07-25|            11599|         CLOSED|\n",
    "|       2|2013-07-25|              256|PENDING_PAYMENT|\n",
    "|       3|2013-07-25|            12111|       COMPLETE|\n",
    "|       4|2013-07-25|             null|         CLOSED|\n",
    "|       5|2013-07-25|            11318|       COMPLETE|\n",
    "|       6|2013-07-25|             null|       COMPLETE|\n",
    "|       7|2013-07-25|             4530|       COMPLETE|\n",
    "+--------+----------+-----------------+---------------+\n",
    "```\n",
    "   \n",
    "We can change this behaviour and we will see next.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e37a35",
   "metadata": {},
   "source": [
    "## Modes of reading data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af3b2d4",
   "metadata": {},
   "source": [
    "When reading data with Spark, there are different modes available to handle corrupt or malformed records encountered during the read process. These modes determine how Spark should behave when it encounters such records.\n",
    "\n",
    "- **Failfast mode:** In this mode (mode=\"failfast\"), Spark fails immediately upon encountering any corrupt or malformed record. It throws an exception and stops the read operation. No data is returned. This mode is useful when you want to ensure data integrity and immediately identify any issues with the data.\n",
    "\n",
    "- **Permissive mode:** Permissive mode (mode=\"permissive\", which is the default) allows Spark to continue reading the data even if it encounters corrupt or malformed records. When a corrupt record is encountered, Spark tries to parse and load as much data as possible. It inserts null or NaN values for the corrupt fields and includes the malformed records in the resulting DataFrame. This mode is helpful when you want to handle corrupt records separately or perform additional error handling.\n",
    "\n",
    "- **Dropmalformed mode:** Dropmalformed mode (mode=\"dropmalformed\") instructs Spark to drop any records that cannot be parsed correctly. When a malformed record is encountered, Spark excludes it from the resulting DataFrame entirely. This mode is useful when you want to discard any records that do not conform to the expected schema or format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a63b948",
   "metadata": {},
   "source": [
    "#### Permissive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a23fd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = 's3://fcc-spark-example/dataset/2023/orders/orders_3.csv/'\n",
    "\n",
    "orders_schema = (StructType()\n",
    "                 .add(StructField('order_id', LongType()))\n",
    "                 .add(StructField('order_date', StringType()))\n",
    "                 .add(StructField('order_customer_id', IntegerType()))\n",
    "                 .add(StructField('order_status', StringType()))\n",
    "                )\n",
    "\n",
    "df = (spark.read\n",
    "           .format('csv')\n",
    "           .schema(orders_schema)\n",
    "           .load(data_set)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b3b9fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------------+---------------+\n",
      "|order_id|order_date|order_customer_id|   order_status|\n",
      "+--------+----------+-----------------+---------------+\n",
      "|       1|   7/25/13|              256|PENDING_PAYMENT|\n",
      "|       2|   7/25/13|            12111|       COMPLETE|\n",
      "|       3|   7/25/13|             8827|         CLOSED|\n",
      "|       4|   7/25/13|            11318|       COMPLETE|\n",
      "|       5|   7/25/13|             null|       COMPLETE|\n",
      "|       6|   7/25/13|             4530|       COMPLETE|\n",
      "|       7|   7/25/13|             2911|     PROCESSING|\n",
      "|       8|   7/25/13|             5657|PENDING_PAYMENT|\n",
      "|       9|   7/25/13|             null|PENDING_PAYMENT|\n",
      "|      10|   7/25/13|              918| PAYMENT_REVIEW|\n",
      "|      11|   7/25/13|             1837|         CLOSED|\n",
      "|      12|   7/25/13|             9149|PENDING_PAYMENT|\n",
      "|      13|   7/25/13|             9842|     PROCESSING|\n",
      "|      14|   7/25/13|             null|       COMPLETE|\n",
      "|      15|   7/25/13|             7276|PENDING_PAYMENT|\n",
      "|      16|   7/25/13|             2667|       COMPLETE|\n",
      "|      17|   7/25/13|             1205|         CLOSED|\n",
      "|      18|   7/25/13|             9488|PENDING_PAYMENT|\n",
      "|      19|   7/25/13|             9198|     PROCESSING|\n",
      "+--------+----------+-----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75e8d3c",
   "metadata": {},
   "source": [
    "#### Failfast mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9e115557",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = 's3://fcc-spark-example/dataset/2023/orders/orders_3.csv/'\n",
    "\n",
    "orders_schema = (StructType()\n",
    "                 .add(StructField('order_id', LongType()))\n",
    "                 .add(StructField('order_date', StringType()))\n",
    "                 .add(StructField('order_customer_id', IntegerType()))\n",
    "                 .add(StructField('order_status', StringType()))\n",
    "                )\n",
    "\n",
    "df = (spark.read\n",
    "           .format('csv')\n",
    "           .schema(orders_schema)\n",
    "           .option('mode', 'failfast')\n",
    "           .load(data_set)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3c808a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This will error out\n",
    "# df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f02cd7",
   "metadata": {},
   "source": [
    "#### Dropmalformed mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca5f828d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------------+---------------+\n",
      "|order_id|order_date|order_customer_id|   order_status|\n",
      "+--------+----------+-----------------+---------------+\n",
      "|       1|   7/25/13|              256|PENDING_PAYMENT|\n",
      "|       2|   7/25/13|            12111|       COMPLETE|\n",
      "|       3|   7/25/13|             8827|         CLOSED|\n",
      "|       4|   7/25/13|            11318|       COMPLETE|\n",
      "|       6|   7/25/13|             4530|       COMPLETE|\n",
      "|       7|   7/25/13|             2911|     PROCESSING|\n",
      "|       8|   7/25/13|             5657|PENDING_PAYMENT|\n",
      "|      10|   7/25/13|              918| PAYMENT_REVIEW|\n",
      "|      11|   7/25/13|             1837|         CLOSED|\n",
      "|      12|   7/25/13|             9149|PENDING_PAYMENT|\n",
      "|      13|   7/25/13|             9842|     PROCESSING|\n",
      "|      15|   7/25/13|             7276|PENDING_PAYMENT|\n",
      "|      16|   7/25/13|             2667|       COMPLETE|\n",
      "|      17|   7/25/13|             1205|         CLOSED|\n",
      "|      18|   7/25/13|             9488|PENDING_PAYMENT|\n",
      "|      19|   7/25/13|             9198|     PROCESSING|\n",
      "+--------+----------+-----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_set = 's3://fcc-spark-example/dataset/2023/orders/orders_3.csv/'\n",
    "\n",
    "orders_schema = (StructType()\n",
    "                 .add(StructField('order_id', LongType()))\n",
    "                 .add(StructField('order_date', StringType()))\n",
    "                 .add(StructField('order_customer_id', IntegerType()))\n",
    "                 .add(StructField('order_status', StringType()))\n",
    "                )\n",
    "\n",
    "df = (spark.read\n",
    "           .format('csv')\n",
    "           .schema(orders_schema)\n",
    "           .option('mode', 'dropmalformed')\n",
    "           .load(data_set)\n",
    "     )\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5451549",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
